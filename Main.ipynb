{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torchvision\n",
    "from torch2trt import TRTModule\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "road_following_model = TRTModule()\n",
    "road_following_model.load_state_dict(torch.load('models/road_following_model_trt.pth'))\n",
    "\n",
    "#\n",
    "\n",
    "block_free_model = TRTModule()\n",
    "block_free_model.load_state_dict(torch.load('models/block_free_model_trt.pth'))\n",
    "\n",
    "#\n",
    "\n",
    "LR_model_trt = TRTModule()\n",
    "LR_model_trt.load_state_dict(torch.load('models/LR_best_model_trt.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 카메라 구동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not initialize camera.  Please see error trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.4.3-py3.6.egg/jetbot/camera/opencv_gst_camera.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Could not read image from camera.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not read image from camera.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-e915275bbcc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjetbot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCamera\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbgr8_to_jpeg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mcamera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCamera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mis_camera_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.4.3-py3.6.egg/jetbot/camera/opencv_gst_camera.py\u001b[0m in \u001b[0;36minstance\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mOpenCvGstCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jetbot-0.4.3-py3.6.egg/jetbot/camera/opencv_gst_camera.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             raise RuntimeError(\n\u001b[0;32m---> 37\u001b[0;31m                 'Could not initialize camera.  Please see error trace.')\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not initialize camera.  Please see error trace."
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(fps=10)\n",
    "is_camera_control = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 젯봇 미세조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c4026399bf4436a43c34e4943e5aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "\n",
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "# steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "# steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "# steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "# display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 얼굴인식 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224\n",
    "height = 224\n",
    "fps = 10\n",
    "\n",
    "fcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "out = cv2.VideoWriter('webcam.avi', fcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('models/haarcascade_frontalface_default.xml')\n",
    "count = 0\n",
    "\n",
    "rate = 15\n",
    "\n",
    "def face_detect(ndarray_image):\n",
    "    #input은 Normalization되지 않은 이미지여야함.    \n",
    "    #image = preprocess(image) #이미지 경량화\n",
    "    \n",
    "    image = ndarray_image    \n",
    "    faces = face_cascade.detectMultiScale(cv2.cvtColor(image,cv2.COLOR_BGR2GRAY),1.3,5)   \n",
    "    global count\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        \n",
    "        if (w or h) == 0: #만약 아무것도 못찾거나 의미가 없으면\n",
    "            return image\n",
    "        \n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        \n",
    "        roi = image[y:y+h, x:x+w]\n",
    "\n",
    "        # 축소\n",
    "        roi = cv2.resize(roi, (w//rate, h//rate))\n",
    "        # INTER_AREA 방식으로 확대\n",
    "        roi = cv2.resize(roi, (w, h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        image[y:y+h, x:x+w] = roi\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 선처리 (Ndarray -> Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \n",
    "    mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "    std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "    \n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road following / block_free 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def road_following(processed_image):\n",
    "    global angle, angle_last\n",
    "    \n",
    "    xy = road_following_model(processed_image).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    #jetbot_spped = speed_gain_slider.value\n",
    "    jetbot_spped = 0.20\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "#     pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "    pid = angle * 0.05 + (angle - angle_last) * 0.00\n",
    "    angle_last = angle\n",
    "    \n",
    "#     steer_bias = pid + steering_bias_slider.value\n",
    "    steer_bias = pid + 0.0\n",
    "    \n",
    "    robot.left_motor.value = max(min(jetbot_spped + steer_bias, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(jetbot_spped - steer_bias, 1.0), 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block_free_detect(processed_image):\n",
    "    global is_camera_control\n",
    "    \n",
    "    bf_detection = block_free_model(processed_image)\n",
    "    bf_detection = F.softmax(bf_detection, dim=1)\n",
    "    \n",
    "    prob_blocked = float(bf_detection.flatten()[0])\n",
    "    \n",
    "    #결과\n",
    "    if prob_blocked < 0.6:        \n",
    "        road_following(processed_image)\n",
    "    \n",
    "    else:        \n",
    "        is_camera_control = False\n",
    "        #robot.stop()\n",
    "        robot.set_motors(0.1, 0.1)\n",
    "        \n",
    "        \n",
    "        #여기에 코드 추가해야함\n",
    "        left_right_detect(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_list = []\n",
    "def left_right_detect(processed_image):\n",
    "    lr_detection = LR_model_trt(processed_image)\n",
    "    lr_detection = F.softmax(lr_detection, dim=1)\n",
    "    \n",
    "    prob_right = float(lr_detection.flatten()[0])\n",
    "    \n",
    "    #결과\n",
    "    if prob_right < 0.5:\n",
    "        #right\n",
    "        print('right')\n",
    "        \n",
    "        if len(LR_list) <3:#의사설정불가\n",
    "            LR_list.append('R')\n",
    "    else:\n",
    "        #left\n",
    "        print('left')\n",
    "        \n",
    "        if len(LR_list) <3:#의사설정불가\n",
    "            LR_list.append('L')\n",
    "    \n",
    "    if len(LR_list) == 3 :\n",
    "        result = max(LR_list, key=LR_list.count)\n",
    "        \n",
    "        if result == 'L':\n",
    "            left_avoidance()\n",
    "        elif result == 'R':\n",
    "            right_avoidance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avoidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_avoidance():\n",
    "    robospeed = 0.14\n",
    "    robot.left(0.185)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    while robospeed > 0.12:\n",
    "        robospeed = robospeed - 0.001\n",
    "        robot.set_motors(0.19, robospeed)\n",
    "        time.sleep(0.15)\n",
    "\n",
    "    \n",
    "    robot.set_motors(0, 0)\n",
    "    \n",
    "    LR_list.clear() #리스트 비우기\n",
    "    \n",
    "\n",
    "def right_avoidance():\n",
    "    robospeed = 0.14\n",
    "    robot.right(0.185)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    while robospeed > 0.12:\n",
    "        robospeed = robospeed - 0.001\n",
    "        robot.set_motors(robospeed, 0.16)\n",
    "        time.sleep(0.15)\n",
    "\n",
    "    \n",
    "    robot.set_motors(0, 0)\n",
    "    \n",
    "    LR_list.clear() #리스트 비우기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main excute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "count = 15\n",
    "def execute(change):\n",
    "    global is_camera_control,count\n",
    "    #chage['new']는 ndarray임.\n",
    "    image = change['new']\n",
    "    \n",
    "    frame = face_detect(image)\n",
    "    out.write(frame)\n",
    "    \n",
    "#     if is_camera_control:\n",
    "#         block_free_detect(preprocess(image))\n",
    "#         count = 15\n",
    "#     else:\n",
    "#         count-=1\n",
    "#         if count==0:\n",
    "#             is_camera_control = True\n",
    "        \n",
    "execute({'new': camera.value})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute로 넘기는부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
